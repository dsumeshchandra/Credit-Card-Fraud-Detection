{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Machine learning Projects'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "os.chdir(\"D:\\\\Machine learning Projects\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['normalizedAmount']= StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data= data.drop(['Amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9        ...              V21       V22       V23  \\\n",
       "0  0.098698  0.363787        ...        -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425        ...        -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654        ...         0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024        ...        -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739        ...        -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normalizedAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0          0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0         -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0          1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0          0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0         -0.073403  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>3.202236e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.023622e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "             ...                  V21           V22           V23  \\\n",
       "count        ...         2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean         ...         1.537294e-16  7.959909e-16  5.367590e-16   \n",
       "std          ...         7.345240e-01  7.257016e-01  6.244603e-01   \n",
       "min          ...        -3.483038e+01 -1.093314e+01 -4.480774e+01   \n",
       "25%          ...        -2.283949e-01 -5.423504e-01 -1.618463e-01   \n",
       "50%          ...        -2.945017e-02  6.781943e-03 -1.119293e-02   \n",
       "75%          ...         1.863772e-01  5.285536e-01  1.476421e-01   \n",
       "max          ...         2.720284e+01  1.050309e+01  2.252841e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.458112e-15  1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16   \n",
       "std    6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01   \n",
       "min   -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01   \n",
       "25%   -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%    4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02   \n",
       "75%    4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02   \n",
       "max    4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   \n",
       "\n",
       "               Class  normalizedAmount  \n",
       "count  284807.000000      2.848070e+05  \n",
       "mean        0.001727      3.202236e-16  \n",
       "std         0.041527      1.000002e+00  \n",
       "min         0.000000     -3.532294e-01  \n",
       "25%         0.000000     -3.308401e-01  \n",
       "50%         0.000000     -2.652715e-01  \n",
       "75%         0.000000     -4.471707e-02  \n",
       "max         1.000000      1.023622e+02  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...              V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794        ...        -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974        ...        -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643        ...         0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952        ...        -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074        ...        -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \\\n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "\n",
       "   normalizedAmount  \n",
       "0          0.244964  \n",
       "1         -0.342475  \n",
       "2          1.160686  \n",
       "3          0.140534  \n",
       "4         -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(['Time'],axis= 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data.iloc[:,data.columns != 'Class']\n",
    "y=data.iloc[:,data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(oob_score= True, n_jobs= -1,n_estimators=100, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99954856443490303"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99950844422597518"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  10\n",
      "OOB score is 0.999342910455\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  20\n",
      "OOB score is 0.999463293273\n",
      "************************\n",
      "For n_estimators=  30\n",
      "OOB score is 0.999498404928\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  40\n",
      "OOB score is 0.999518468731\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  50\n",
      "OOB score is 0.999518468731\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  60\n",
      "OOB score is 0.999523484681\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  70\n",
      "OOB score is 0.999548564435\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  80\n",
      "OOB score is 0.999543548484\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  90\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  100\n",
      "OOB score is 0.999548564435\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  110\n",
      "OOB score is 0.999543548484\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  120\n",
      "OOB score is 0.999533516583\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  130\n",
      "OOB score is 0.999533516583\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  140\n",
      "OOB score is 0.999543548484\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  150\n",
      "OOB score is 0.999533516583\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  160\n",
      "OOB score is 0.999538532533\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  170\n",
      "OOB score is 0.999538532533\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  180\n",
      "OOB score is 0.999543548484\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  190\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  200\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  210\n",
      "OOB score is 0.999543548484\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  220\n",
      "OOB score is 0.999548564435\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  230\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  240\n",
      "OOB score is 0.999543548484\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  250\n",
      "OOB score is 0.999558596336\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  260\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  270\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  280\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=  290\n",
      "OOB score is 0.999553580386\n",
      "************************\n"
     ]
    }
   ],
   "source": [
    "for w in range(10,100,10):\n",
    "    rf1=RandomForestClassifier(oob_score=True,n_jobs=-1,n_estimators=w,random_state=0)\n",
    "                        \n",
    "    rf1.fit(X_train,y_train)\n",
    "    oob=rf1.oob_score_\n",
    "    print(\"For n_estimators=  \"+str(w)) \n",
    "    print('OOB score is '+str(oob))\n",
    "    print('************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizing model with 90 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99950844422597518"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2= RandomForestClassifier(oob_score=True,n_jobs=-1,n_estimators=90,random_state=0)\n",
    "rf2.fit(X_train,y_train)\n",
    "rf2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99955358038562625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred1=rf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix1=confusion_matrix(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[85289     7]\n",
      " [   35   112]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAEYCAYAAADRWAT6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng6SZWRH/H7QB3jwyk829AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc87bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix1,classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2=rf2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix2=confusion_matrix(y,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[284308      7]\n",
      " [    35    457]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAEYCAYAAADcRnS9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlaC/w+w5me5tRL9CQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc900cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix2,classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=209652396, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=398764591, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=924231285, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1478610112, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=441365315, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1537364731, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=192771779, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1491434855, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1819583497, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=530702035, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=626610453, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1650906866, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1879422756, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1277901399, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1682652230, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=243580376, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1991416408, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1171049868, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1646868794, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2051556033, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1252949478, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1340754471, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=124102743, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2061486254, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=292249176, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1686997841, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1827923621, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1443447321, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=305097549, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1449105480, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=374217481, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=636393364, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=86837363, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1581585360, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1428591347, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1963466437, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1194674174, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=602801999, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1589190063, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1589512640, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2055650130, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2034131043, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1284876248, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1292401841, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1982038771, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=87950109, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1204863635, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=768281747, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=507984782, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=947610023, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=600956192, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=352272321, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=615697673, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=160516793, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1909838463, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1110745632, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=93837855, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=454869706, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1780959476, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2034098327, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1136257699, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=800291326, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1177824715, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1017555826, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1959150775, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=930076700, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=293921570, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=580757632, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=80701568, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1392175012, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=505240629, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=642848645, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=481447462, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=954863080, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=502227700, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1659957521, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1905883471, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1729147268, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=780912233, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1932520490, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1544074682, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=485603871, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1877037944, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1728073985, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=848819521, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=426405863, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=258666409, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2017814585, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=716257571, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=657731430, splitter='best')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False,\n",
       "            random_state=209652396, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0144317 ,  0.01393689,  0.01669235,  0.03007477,  0.01235541,\n",
       "        0.01559151,  0.01702907,  0.0107254 ,  0.03164974,  0.06828563,\n",
       "        0.07869804,  0.12863417,  0.01218882,  0.13369467,  0.01301662,\n",
       "        0.04536234,  0.17717721,  0.04428193,  0.01154311,  0.01073595,\n",
       "        0.02366567,  0.01038541,  0.00697518,  0.00951633,  0.00831852,\n",
       "        0.01875993,  0.01427523,  0.01177888,  0.01021949])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_features=pd.Series(rf2.feature_importances_,index=X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V17                 0.177177\n",
       "V14                 0.133695\n",
       "V12                 0.128634\n",
       "V11                 0.078698\n",
       "V10                 0.068286\n",
       "V16                 0.045362\n",
       "V18                 0.044282\n",
       "V9                  0.031650\n",
       "V4                  0.030075\n",
       "V21                 0.023666\n",
       "V26                 0.018760\n",
       "V7                  0.017029\n",
       "V3                  0.016692\n",
       "V6                  0.015592\n",
       "V1                  0.014432\n",
       "V27                 0.014275\n",
       "V2                  0.013937\n",
       "V15                 0.013017\n",
       "V5                  0.012355\n",
       "V13                 0.012189\n",
       "V28                 0.011779\n",
       "V19                 0.011543\n",
       "V20                 0.010736\n",
       "V8                  0.010725\n",
       "V22                 0.010385\n",
       "normalizedAmount    0.010219\n",
       "V24                 0.009516\n",
       "V25                 0.008319\n",
       "V23                 0.006975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_features.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc8d2128>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAFRCAYAAAB0TtpPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUvP/AbHl37+vuoTXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa22bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_features.sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
